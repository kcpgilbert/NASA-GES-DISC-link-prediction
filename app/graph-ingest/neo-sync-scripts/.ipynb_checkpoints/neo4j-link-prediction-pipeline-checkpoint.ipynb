{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#from py2neo import Graph, Node, Relationship\n",
    "#from graphdatascience import GraphDataScience\n",
    "\n",
    "# Get Neo4j client\n",
    "#graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"linkprediction\"))\n",
    "\n",
    "\n",
    "##drop functions for pipeline, prediction graph, and model, comment out function call if not needed\n",
    "#drop_pipeline = f'''\n",
    " #   CALL gds.beta.pipeline.drop('pipe', False)\n",
    "#'''\n",
    "#drop_prediction_graph = f'''\n",
    "#    CALL gds.graph.drop('prediction_graph', False)\n",
    "#'''\n",
    "#drop_model = f'''\n",
    "#    CALL gds.beta.model.drop('lp_model', False)\n",
    "#'''\n",
    "#graph.run(drop_pipeline)\n",
    "#graph.run(drop_prediction_graph)\n",
    "#graph.run(drop_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Connect to Neo4j database\n",
    "uri = \"bolt://neo4j_instance_test:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"kendallg\"\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Define Cypher queries for dropping pipeline, prediction graph, and model\n",
    "drop_pipeline = '''\n",
    "    CALL gds.beta.pipeline.drop('pipe', false)\n",
    "'''\n",
    "drop_prediction_graph = '''\n",
    "    CALL gds.graph.drop('prediction_graph', false)\n",
    "'''\n",
    "drop_model = '''\n",
    "    CALL gds.beta.model.drop('lp_model', false)\n",
    "'''\n",
    "\n",
    "# Execute queries\n",
    "with driver.session() as session:\n",
    "    session.run(drop_pipeline)\n",
    "    session.run(drop_prediction_graph)\n",
    "    session.run(drop_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create prediction graph\n",
    "\n",
    "#format_relationships = '''\n",
    "#{\n",
    "#HAS_KEYWORD: {orientation: 'UNDIRECTED'}\n",
    "#}\n",
    "#'''\n",
    "\n",
    "#create_prediction_graph = f'''\n",
    "#    CALL gds.graph.project(\n",
    "#        'prediction_graph', \n",
    "#        ['Dataset', 'Keyword', 'Platform', 'Instrument', 'Investigator'],\n",
    "#        {format_relationships}\n",
    "#    )\n",
    "#'''\n",
    "\n",
    "#graph.run(create_prediction_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction graph exists: False\n"
     ]
    }
   ],
   "source": [
    "# Define the format of relationships\n",
    "format_relationships = {\n",
    "    'HAS_KEYWORD': {'orientation': 'UNDIRECTED'}\n",
    "}\n",
    "\n",
    "\n",
    "# Define Cypher query for creating the prediction graph\n",
    "create_prediction_graph = '''\n",
    "    CALL gds.graph.project(\n",
    "        'prediction_graph', \n",
    "        ['Dataset', 'ScienceKeyword', 'Platform', 'Instrument', 'Investigator'],\n",
    "        $format_relationships\n",
    "    )\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "with driver.session() as session:\n",
    "    session.run(create_prediction_graph, format_relationships=format_relationships)\n",
    "\n",
    "# Define Cypher query to confirm the creation of the prediction graph\n",
    "confirm_prediction_graph = '''\n",
    "    CALL gds.graph.exists('prediction_graph') YIELD exists\n",
    "    RETURN exists\n",
    "'''\n",
    "\n",
    "# Execute the confirmation query and print the result\n",
    "with driver.session() as session:\n",
    "    result = session.run(confirm_prediction_graph)\n",
    "    for record in result:\n",
    "        print(f\"Prediction graph exists: {record['exists']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create/config pipeline\n",
    "#create_pipeline = f'''\n",
    "#    CALL gds.beta.pipeline.linkPrediction.create('pipe')\n",
    "#'''\n",
    "\n",
    "#graph.run(create_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Cypher query for creating the pipeline\n",
    "create_pipeline = '''\n",
    "    CALL gds.beta.pipeline.linkPrediction.create('pipe')\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "with driver.session() as session:\n",
    "    session.run(create_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split config\n",
    "#split_config = '''\n",
    "#{\n",
    "#    testFraction: 0.6,\n",
    "#    trainFraction: 0.25,\n",
    "#    validationFolds: 3\n",
    "#}\n",
    "#'''\n",
    "\n",
    "#splits = f'''\n",
    "#    CALL gds.beta.pipeline.linkPrediction.configureSplit('pipe', {split_config})\n",
    "#'''\n",
    "\n",
    "#graph.run(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split configuration\n",
    "split_config = {\n",
    "    \"testFraction\": 0.6,\n",
    "    \"trainFraction\": 0.25,\n",
    "    \"validationFolds\": 3\n",
    "}\n",
    "\n",
    "# Define Cypher query for configuring the split\n",
    "configure_split = '''\n",
    "    CALL gds.beta.pipeline.linkPrediction.configureSplit('pipe', $split_config)\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "with driver.session() as session:\n",
    "    session.run(configure_split, split_config=split_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add features to pipeline object before training, need at least one\n",
    "\n",
    "#fastrp\n",
    "# fastrp_config = '''\n",
    "# {\n",
    "#     mutateProperty: 'fastRP', \n",
    "#     embeddingDimension: 56, \n",
    "#     randomSeed: 42\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# fastrp = f'''\n",
    "#     CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'fastRP', {fastrp_config})\n",
    "# '''\n",
    "\n",
    "# graph.run(fastrp)\n",
    "\n",
    "# #degree\n",
    "# degree_config = '''\n",
    "# {\n",
    "#     mutateProperty: 'degree'\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# degree = f'''\n",
    "#     CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'degree', {degree_config})\n",
    "# '''\n",
    "\n",
    "# graph.run(degree)\n",
    "\n",
    "# #scaled degree\n",
    "# scaled_config = '''\n",
    "# {\n",
    "#     nodeProperties: ['degree'],\n",
    "#     mutateProperty: 'scaledDegree', \n",
    "#     scaler: 'Mean'\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# scaled = f'''\n",
    "#     CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'alpha.scaleProperties', {scaled_config})\n",
    "# '''\n",
    "\n",
    "# graph.run(scaled)\n",
    "\n",
    "# #article rank (less emphasize on low degree nodes)\n",
    "# article_rank_config = '''\n",
    "# {\n",
    "#     mutateProperty: 'articleRank'\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# article_rank = f'''\n",
    "#     CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'articleRank', {article_rank_config})\n",
    "# '''\n",
    "\n",
    "# graph.run(article_rank)\n",
    "\n",
    "# #closeness (prioritizing nodes that are topoligically close to all other nodes)\n",
    "# closeness_config = '''\n",
    "# {\n",
    "#     mutateProperty: 'closeness'\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# closeness = f'''\n",
    "#     CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'closeness', {closeness_config})\n",
    "# '''\n",
    "\n",
    "# graph.run(closeness)\n",
    "\n",
    "# #CELF, set of nodes with maximum spread\n",
    "# celf_config = '''\n",
    "# {\n",
    "#     mutateProperty: 'celf',\n",
    "#     seedSetSize: 20\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# celf = f'''\n",
    "#     CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'influenceMaximization.celf', {celf_config})\n",
    "# '''\n",
    "\n",
    "# graph.run(celf)\n",
    "\n",
    "# #page rank, quality of connected links (more emphasize on nodes that have links with other high degree nodes)\n",
    "# page_rank_config = '''\n",
    "# {\n",
    "#     mutateProperty: 'pageRank'\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# page_rank = f'''\n",
    "#     CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'pageRank', {page_rank_config})\n",
    "# '''\n",
    "\n",
    "# graph.run(page_rank)\n",
    "\n",
    "\n",
    "# #add features\n",
    "# node_properties = '''\n",
    "# {\n",
    "#     nodeProperties: ['fastRP', 'scaledDegree', 'articleRank', 'pageRank']\n",
    "# }\n",
    "# '''\n",
    "\n",
    "\n",
    "# add_link_features = f'''\n",
    "#     CALL gds.beta.pipeline.linkPrediction.addFeature('pipe', 'HADAMARD', {node_properties})\n",
    "# '''\n",
    "\n",
    "# graph.run(add_link_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configurations for different features\n",
    "fastrp_config = {\n",
    "    \"mutateProperty\": \"fastRP\",\n",
    "    \"embeddingDimension\": 56,\n",
    "    \"randomSeed\": 42\n",
    "}\n",
    "\n",
    "degree_config = {\n",
    "    \"mutateProperty\": \"degree\"\n",
    "}\n",
    "\n",
    "scaled_config = {\n",
    "    \"nodeProperties\": [\"degree\"],\n",
    "    \"mutateProperty\": \"scaledDegree\",\n",
    "    \"scaler\": \"Mean\"\n",
    "}\n",
    "\n",
    "article_rank_config = {\n",
    "    \"mutateProperty\": \"articleRank\"\n",
    "}\n",
    "\n",
    "closeness_config = {\n",
    "    \"mutateProperty\": \"closeness\"\n",
    "}\n",
    "\n",
    "celf_config = {\n",
    "    \"mutateProperty\": \"celf\",\n",
    "    \"seedSetSize\": 20\n",
    "}\n",
    "\n",
    "page_rank_config = {\n",
    "    \"mutateProperty\": \"pageRank\"\n",
    "}\n",
    "\n",
    "# Define node properties for adding link features as a dictionary\n",
    "node_properties = {\n",
    "    \"nodeProperties\": ['fastRP', 'scaledDegree', 'articleRank', 'pageRank']\n",
    "}\n",
    "\n",
    "# Define Cypher queries for adding different features\n",
    "add_fastrp = '''\n",
    "    CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'fastRP', $fastrp_config)\n",
    "'''\n",
    "\n",
    "add_degree = '''\n",
    "    CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'degree', $degree_config)\n",
    "'''\n",
    "\n",
    "add_scaled = '''\n",
    "    CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'alpha.scaleProperties', $scaled_config)\n",
    "'''\n",
    "\n",
    "add_article_rank = '''\n",
    "    CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'articleRank', $article_rank_config)\n",
    "'''\n",
    "\n",
    "add_closeness = '''\n",
    "    CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'closeness', $closeness_config)\n",
    "'''\n",
    "\n",
    "add_celf = '''\n",
    "    CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'influenceMaximization.celf', $celf_config)\n",
    "'''\n",
    "\n",
    "add_page_rank = '''\n",
    "    CALL gds.beta.pipeline.linkPrediction.addNodeProperty('pipe', 'pageRank', $page_rank_config)\n",
    "'''\n",
    "\n",
    "add_link_features = '''\n",
    "    CALL gds.beta.pipeline.linkPrediction.addFeature('pipe', 'HADAMARD', $node_properties)\n",
    "'''\n",
    "\n",
    "# Execute the queries\n",
    "with driver.session() as session:\n",
    "    session.run(add_fastrp, fastrp_config=fastrp_config)\n",
    "    session.run(add_degree, degree_config=degree_config)\n",
    "    session.run(add_scaled, scaled_config=scaled_config)\n",
    "    session.run(add_article_rank, article_rank_config=article_rank_config)\n",
    "    session.run(add_closeness, closeness_config=closeness_config)\n",
    "    session.run(add_celf, celf_config=celf_config)\n",
    "    session.run(add_page_rank, page_rank_config=page_rank_config)\n",
    "    session.run(add_link_features, node_properties=node_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model candidate(s)\n",
    "\n",
    "# logistic_regression = f'''\n",
    "#    CALL gds.beta.pipeline.linkPrediction.addLogisticRegression('pipe')\n",
    "# '''\n",
    "\n",
    "# #graph.run(logistic_regression)\n",
    "\n",
    "# #numberOfSamplesRatio comes from the true class ratio of the database, to \n",
    "# #counteract class imbalance. The true class ratio of the database is calcuated as \n",
    "# empty_brace = '''\n",
    "# {\n",
    "# numberOfSamplesRatio: .07\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# random_forest = f'''\n",
    "#     CALL gds.beta.pipeline.linkPrediction.addRandomForest('pipe', {empty_brace})\n",
    "# '''\n",
    "\n",
    "# graph.run(random_forest)\n",
    "\n",
    "# MLP = f'''\n",
    "#     CALL gds.alpha.pipeline.linkPrediction.addMLP('pipe')\n",
    "# '''\n",
    "\n",
    "#graph.run(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Cypher queries for adding model candidates\n",
    "add_logistic_regression = '''\n",
    "   CALL gds.beta.pipeline.linkPrediction.addLogisticRegression('pipe');\n",
    "'''\n",
    "\n",
    "add_random_forest = '''\n",
    "    CALL gds.beta.pipeline.linkPrediction.addRandomForest('pipe', $empty_brace);\n",
    "'''\n",
    "\n",
    "add_mlp = '''\n",
    "    CALL gds.alpha.pipeline.linkPrediction.addMLP('pipe');\n",
    "'''\n",
    "\n",
    "# Define empty brace as a dictionary\n",
    "empty_brace = {\n",
    "    \"numberOfSamplesRatio\": 0.07\n",
    "}\n",
    "\n",
    "# Execute the queries\n",
    "with driver.session() as session:\n",
    "    # Add Logistic Regression (commented out in the original script)\n",
    "    # session.run(add_logistic_regression)\n",
    "    \n",
    "    # Add Random Forest with empty brace configuration\n",
    "    session.run(add_random_forest, empty_brace=empty_brace)\n",
    "    \n",
    "    # MLP was never run, so not included in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train pipeline 0.00711986262\n",
    "\n",
    "# train_config = '''\n",
    "# {\n",
    "# pipeline: 'pipe',\n",
    "# modelName: 'lp_model',\n",
    "# targetRelationshipType: 'HAS_KEYWORD',\n",
    "# metrics: ['AUCPR'],\n",
    "# randomSeed: 42\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# train_pipeline = f'''\n",
    "#     CALL gds.beta.pipeline.linkPrediction.train('prediction_graph', {train_config})\n",
    "#     YIELD modelInfo, modelSelectionStats\n",
    "#     RETURN\n",
    "#       modelInfo.bestParameters AS winningModel,\n",
    "#     modelInfo.metrics.AUCPR.train.avg AS avgTrainScore,\n",
    "#     modelInfo.metrics.AUCPR.outerTrain AS outerTrainScore,\n",
    "#     modelInfo.metrics.AUCPR.test AS testScore,\n",
    "#     [candidate IN modelSelectionStats.modelCandidates | candidate.metrics.AUCPR.validation.avg] AS validationScores\n",
    "# '''\n",
    "\n",
    "# graph.run(train_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "{code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `gds.beta.pipeline.linkPrediction.train`: Caused by: java.util.NoSuchElementException: Graph with name `prediction_graph` does not exist on database `neo4j`. It might exist on another database.}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m driver\u001b[38;5;241m.\u001b[39msession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m     24\u001b[0m     result \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mrun(train_pipeline, train_config\u001b[38;5;241m=\u001b[39mtrain_config)\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWinning Model:\u001b[39m\u001b[38;5;124m\"\u001b[39m, record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwinningModel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Train Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavgTrainScore\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/neo4j/_sync/work/result.py:251\u001b[0m, in \u001b[0;36mResult.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_buffer\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming:\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_discarding:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_discard()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/neo4j/_sync/io/_common.py:180\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39miscoroutinefunction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__on_error)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/neo4j/_sync/io/_bolt.py:851\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[1;32m    848\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[1;32m    849\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[1;32m    850\u001b[0m )\n\u001b[0;32m--> 851\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/neo4j/_sync/io/_bolt4.py:372\u001b[0m, in \u001b[0;36mBolt4x0._process_message\u001b[0;34m(self, tag, fields)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_state_manager\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m BoltStates\u001b[38;5;241m.\u001b[39mFAILED\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/neo4j/_sync/io/_common.py:247\u001b[0m, in \u001b[0;36mResponse.on_failure\u001b[0;34m(self, metadata)\u001b[0m\n\u001b[1;32m    245\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandlers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Neo4jError\u001b[38;5;241m.\u001b[39mhydrate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata)\n",
      "\u001b[0;31mClientError\u001b[0m: {code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `gds.beta.pipeline.linkPrediction.train`: Caused by: java.util.NoSuchElementException: Graph with name `prediction_graph` does not exist on database `neo4j`. It might exist on another database.}"
     ]
    }
   ],
   "source": [
    "# Define the Cypher query\n",
    "train_pipeline = '''\n",
    "    CALL gds.beta.pipeline.linkPrediction.train('prediction_graph', $train_config)\n",
    "    YIELD modelInfo, modelSelectionStats\n",
    "    RETURN\n",
    "      modelInfo.bestParameters AS winningModel,\n",
    "      modelInfo.metrics.AUCPR.train.avg AS avgTrainScore,\n",
    "      modelInfo.metrics.AUCPR.outerTrain AS outerTrainScore,\n",
    "      modelInfo.metrics.AUCPR.test AS testScore,\n",
    "      [candidate IN modelSelectionStats.modelCandidates | candidate.metrics.AUCPR.validation.avg] AS validationScores\n",
    "'''\n",
    "\n",
    "# Define the train_config as a dictionary\n",
    "train_config = {\n",
    "    \"pipeline\": \"pipe\",\n",
    "    \"modelName\": \"lp_model\",\n",
    "    \"targetRelationshipType\": \"HAS_KEYWORD\",\n",
    "    \"metrics\": [\"AUCPR\"],\n",
    "    \"randomSeed\": 42\n",
    "}\n",
    "\n",
    "# Execute the query and print the results\n",
    "with driver.session() as session:\n",
    "    result = session.run(train_pipeline, train_config=train_config)\n",
    "    for record in result:\n",
    "        print(\"Winning Model:\", record[\"winningModel\"])\n",
    "        print(\"Average Train Score:\", record[\"avgTrainScore\"])\n",
    "        print(\"Outer Train Score:\", record[\"outerTrainScore\"])\n",
    "        print(\"Test Score:\", record[\"testScore\"])\n",
    "        print(\"Validation Scores:\", record[\"validationScores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #predict\n",
    "# predict_config_mutate = '''\n",
    "# {\n",
    "# modelName: 'lp_model',\n",
    "# mutateRelationshipType: 'HAS_KEYWORD_EXHAUSTIVE_PREDICTED',\n",
    "# topN: 40,\n",
    "# threshold: 0.5\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# predict_config_stream = '''\n",
    "# {\n",
    "# modelName: 'lp_model',\n",
    "# sampleRate: 1,\n",
    "# topN: 1000,\n",
    "# threshold: .5\n",
    "# }\n",
    "# ''' \n",
    "\n",
    "# #use stream to see predicted pairings probilities, mutate to change the prediction graph\n",
    "# predict_stream = f'''\n",
    "#     CALL gds.beta.pipeline.linkPrediction.predict.stream('prediction_graph', {predict_config_stream})\n",
    "#     YIELD node1, node2, probability\n",
    "#     WHERE (gds.util.asNode(node1).longName IS NOT NULL OR gds.util.asNode(node2).longName IS NOT NULL)\n",
    "#     AND\n",
    "#     (gds.util.asNode(node1).name IS NOT NULL OR gds.util.asNode(node2).name IS NOT NULL)\n",
    "    \n",
    "#     RETURN \n",
    "#     CASE \n",
    "#         WHEN gds.util.asNode(node1).shortName IS NOT NULL then gds.util.asNode(node1).shortName\n",
    "#         ELSE gds.util.asNode(node2).shortName\n",
    "#     END AS DATASET_SHORT,\n",
    "    \n",
    "#     CASE\n",
    "#         WHEN gds.util.asNode(node1).name IS NOT NULL then gds.util.asNode(node1).name\n",
    "#         ELSE gds.util.asNode(node2).name\n",
    "#     END AS KEYWORD,\n",
    "\n",
    "#     probability,\n",
    "\n",
    "#     CASE \n",
    "#         WHEN gds.util.asNode(node1).longName IS NOT NULL then gds.util.asNode(node1).longName\n",
    "#         ELSE gds.util.asNode(node2).longName\n",
    "#     END AS DATASET_LONG,\n",
    "\n",
    "#     CASE \n",
    "#         WHEN gds.util.asNode(node1).longName IS NOT NULL then node1\n",
    "#         ELSE node2\n",
    "#     END AS DATASET_NODE_ID,\n",
    "\n",
    "#     CASE\n",
    "#         WHEN gds.util.asNode(node1).name IS NOT NULL then node1\n",
    "#         ELSE node2\n",
    "#     END AS KEYWORD_NODE_ID\n",
    "# '''\n",
    "# ###WITH STREAM COPY PASTE BELOW DIRECTLY INTO NEO4j DESKTOP, VSCODE DISPLAY ISSUE???\n",
    "\n",
    "# '''\n",
    "# CALL gds.beta.pipeline.linkPrediction.predict.stream('prediction_graph', {\n",
    "# modelName: 'lp_model',\n",
    "# sampleRate: 1,\n",
    "# topN: 1000,\n",
    "# threshold: .85})\n",
    "# YIELD node1, node2, probability\n",
    "# WHERE (gds.util.asNode(node1).shortName IS NOT NULL OR gds.util.asNode(node2).shortName IS NOT NULL)\n",
    "# AND\n",
    "# (gds.util.asNode(node1).name IS NOT NULL OR gds.util.asNode(node2).name IS NOT NULL)\n",
    "\n",
    "# RETURN \n",
    "#     CASE \n",
    "#         WHEN gds.util.asNode(node1).shortName IS NOT NULL then gds.util.asNode(node1).shortName\n",
    "#         ELSE gds.util.asNode(node2).shortName\n",
    "#     END AS DATASET_SHORT,\n",
    "\n",
    "#     CASE\n",
    "#         WHEN gds.util.asNode(node1).name IS NOT NULL then gds.util.asNode(node1).name\n",
    "#         ELSE gds.util.asNode(node2).name\n",
    "#     END AS KEYWORD,\n",
    "\n",
    "#     probability,\n",
    "\n",
    "#     CASE \n",
    "#         WHEN gds.util.asNode(node1).longName IS NOT NULL then gds.util.asNode(node1).longName\n",
    "#         ELSE gds.util.asNode(node2).longName\n",
    "#     END AS DATASET_LONG,\n",
    "\n",
    "#     CASE \n",
    "#         WHEN gds.util.asNode(node1).shortName IS NOT NULL then node1\n",
    "#         ELSE node2\n",
    "#     END AS DATASET_NODE_ID,\n",
    "\n",
    "#     CASE\n",
    "#         WHEN gds.util.asNode(node1).name IS NOT NULL then node1\n",
    "#         ELSE node2\n",
    "#     END AS KEYWORD_NODE_ID\n",
    "# '''\n",
    "\n",
    "# predict_mutate = f'''\n",
    "#     CALL gds.beta.pipeline.linkPrediction.predict.mutate('prediction_graph', {predict_config_mutate})\n",
    "# '''\n",
    "\n",
    "# graph.run(predict_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     DATASET_SHORT                   KEYWORD  probability  \\\n",
      "0  SNDRAQIML3CMCCP             surface winds          1.0   \n",
      "1         TOVSA5ND        precipitation rate          1.0   \n",
      "2         TOVSA5ND          surface pressure          1.0   \n",
      "3    MAT1NXSLV_CPR          skin temperature          1.0   \n",
      "4     PET_PU_3H025     upper air temperature          1.0   \n",
      "5         TOVSBMNG  total precipitable water          1.0   \n",
      "6         TOVSBMNG           air temperature          1.0   \n",
      "7        GSSTF_F08          surface pressure          1.0   \n",
      "8   SNDRAQIL3SMCCP             surface winds          1.0   \n",
      "9        M2T1NXOCN             surface winds          1.0   \n",
      "\n",
      "                                        DATASET_LONG  DATASET_NODE_ID  \\\n",
      "0  Sounder SIPS: AQUA AIRS IR + MW Level 3 CLIMCA...              772   \n",
      "1  TOVS GLA 5 DAY GRIDS from NOAA-12 V01 (TOVSA5N...             1485   \n",
      "2  TOVS GLA 5 DAY GRIDS from NOAA-12 V01 (TOVSA5N...             1485   \n",
      "3  MERRA 2D IAU Diagnostic, Single Level Meteorol...             1462   \n",
      "4  RM-OBS/PU Potential Evapotranspiration and Sup...              817   \n",
      "5  TOVS LMD MONTHLY GRIDS from NOAA-10 V01 (TOVSB...             1533   \n",
      "6  TOVS LMD MONTHLY GRIDS from NOAA-10 V01 (TOVSB...             1533   \n",
      "7  Goddard Satellite-Based Surface Turbulent Flux...             1436   \n",
      "8  Sounder SIPS: AQUA AIRS IR-only Level 3 CLIMCA...             1528   \n",
      "9  MERRA-2 tavg1_2d_ocn_Nx: 2d,1-Hourly,Time-Aver...             1518   \n",
      "\n",
      "   KEYWORD_NODE_ID  \n",
      "0             1749  \n",
      "1             1714  \n",
      "2             1668  \n",
      "3             1628  \n",
      "4             1670  \n",
      "5             1685  \n",
      "6             1680  \n",
      "7             1668  \n",
      "8             1749  \n",
      "9             1749  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the configuration for mutation and streaming predictions\n",
    "predict_config_mutate = {\n",
    "    \"modelName\": \"lp_model\",\n",
    "    \"mutateRelationshipType\": \"HAS_KEYWORD_EXHAUSTIVE_PREDICTED\",\n",
    "    \"topN\": 40,\n",
    "    \"threshold\": 0.5\n",
    "}\n",
    "\n",
    "predict_config_stream = {\n",
    "    \"modelName\": \"lp_model\",\n",
    "    \"sampleRate\": 1,\n",
    "    \"topN\": 1000,\n",
    "    \"threshold\": 0.5\n",
    "}\n",
    "\n",
    "# Define the Cypher query for streaming prediction\n",
    "predict_stream_query = \"\"\"\n",
    "CALL gds.beta.pipeline.linkPrediction.predict.stream('prediction_graph', $predict_config_stream)\n",
    "YIELD node1, node2, probability\n",
    "WHERE (gds.util.asNode(node1).longName IS NOT NULL OR gds.util.asNode(node2).longName IS NOT NULL)\n",
    "AND (gds.util.asNode(node1).name IS NOT NULL OR gds.util.asNode(node2).name IS NOT NULL)\n",
    "RETURN \n",
    "    CASE \n",
    "        WHEN gds.util.asNode(node1).shortName IS NOT NULL THEN gds.util.asNode(node1).shortName\n",
    "        ELSE gds.util.asNode(node2).shortName\n",
    "    END AS DATASET_SHORT,\n",
    "    \n",
    "    CASE\n",
    "        WHEN gds.util.asNode(node1).name IS NOT NULL THEN gds.util.asNode(node1).name\n",
    "        ELSE gds.util.asNode(node2).name\n",
    "    END AS KEYWORD,\n",
    "    \n",
    "    probability,\n",
    "    \n",
    "    CASE \n",
    "        WHEN gds.util.asNode(node1).longName IS NOT NULL THEN gds.util.asNode(node1).longName\n",
    "        ELSE gds.util.asNode(node2).longName\n",
    "    END AS DATASET_LONG,\n",
    "    \n",
    "    CASE \n",
    "        WHEN gds.util.asNode(node1).longName IS NOT NULL THEN node1\n",
    "        ELSE node2\n",
    "    END AS DATASET_NODE_ID,\n",
    "    \n",
    "    CASE\n",
    "        WHEN gds.util.asNode(node1).name IS NOT NULL THEN node1\n",
    "        ELSE node2\n",
    "    END AS KEYWORD_NODE_ID\n",
    "\"\"\"\n",
    "\n",
    "# Define the Cypher query for mutation prediction\n",
    "predict_mutate_query = \"\"\"\n",
    "CALL gds.beta.pipeline.linkPrediction.predict.mutate('prediction_graph', $predict_config_mutate)\n",
    "\"\"\"\n",
    "\n",
    "# Execute the Cypher query for streaming prediction\n",
    "with driver.session() as session:\n",
    "    result = session.run(predict_stream_query, predict_config_stream=predict_config_stream)\n",
    "    results_list = [dict(record) for record in result]\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "df = pd.DataFrame(results_list)\n",
    "\n",
    "# Display the first 10 rows of the DataFrame\n",
    "print(df.head(10))\n",
    "\n",
    "# Execute the Cypher query for mutation prediction\n",
    "#with driver.session() as session:\n",
    "    #session.run(predict_mutate_query, predict_config_mutate=predict_config_mutate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('PredictedKeywords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rerun algorithms on graph and stream if needed\n",
    "# #fastrp\n",
    "# mutate_fastrp_config = '''\n",
    "# {\n",
    "#     mutateProperty: 'fastRP', \n",
    "#     embeddingDimension: 56, \n",
    "#     randomSeed: 42\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# mutate_fastrp = f'''\n",
    "#     CALL gds.fastRP.mutate('prediction_graph', {mutate_fastrp_config})\n",
    "# '''\n",
    "\n",
    "# #degree\n",
    "# mutate_degree_config = '''\n",
    "# {\n",
    "#     mutateProperty: 'degree'\n",
    "# }\n",
    "# # '''\n",
    "\n",
    "# mutate_degree = f'''\n",
    "#     CALL gds.degree.mutate('prediction_graph', {mutate_degree_config})\n",
    "# '''\n",
    "\n",
    "\n",
    "# #scaled degree\n",
    "# mutate_scaled_config = '''\n",
    "# {\n",
    "#     nodeProperties: ['degree'],\n",
    "#     mutateProperty: 'scaledDegree', \n",
    "#     scaler: 'Mean'\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# mutate_scaled = f'''\n",
    "#     CALL gds.scaleProperties.mutate('prediction_graph', {mutate_scaled_config})\n",
    "# '''\n",
    "\n",
    "\n",
    "# #article rank\n",
    "# mutate_article_rank_config = '''\n",
    "# {\n",
    "#     mutateProperty: 'articleRank'\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# mutate_article_rank = f'''\n",
    "#     CALL gds.articleRank.mutate('prediction_graph', {mutate_article_rank_config})\n",
    "# '''\n",
    "\n",
    "# #closeness \n",
    "# mutate_closeness_config = '''\n",
    "# {\n",
    "#     mutateProperty: 'closeness'\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# mutate_closeness = f'''\n",
    "#     CALL gds.betweenness.mutate('prediction_graph', {mutate_closeness_config})\n",
    "# '''\n",
    "\n",
    "# stream_node_properties = f'''\n",
    "#     CALL gds.graph.nodeProperties.stream('prediction_graph', ['fastRP', 'degree', 'scaledDegree', 'articleRank', 'closeness'])\n",
    "#     YIELD nodeId, nodeProperty, propertyValue\n",
    "#     RETURN nodeId AS ID, gds.util.asNode(nodeId).shortName AS datasetName, gds.util.asNode(nodeId).name AS keywordName, nodeProperty, propertyValue\n",
    "# '''\n",
    "# ##copy and paste above cypher and run directly in neo4j desktop to avoid jupyter notebook cutting off output\n",
    "\n",
    "\n",
    "# #must comment all below when wanting to run predictions in neo4j desktop\n",
    "# #graph.run(mutate_fastrp)\n",
    "# #graph.run(mutate_degree)\n",
    "# #graph.run(mutate_scaled)\n",
    "# #graph.run(mutate_article_rank)\n",
    "# #graph.run(mutate_closeness)\n",
    "# #graph.run(stream_node_properties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration for mutating algorithms\n",
    "mutate_fastrp_config = {\n",
    "    \"mutateProperty\": \"fastRP\",\n",
    "    \"embeddingDimension\": 56,\n",
    "    \"randomSeed\": 42\n",
    "}\n",
    "\n",
    "mutate_degree_config = {\n",
    "    \"mutateProperty\": \"degree\"\n",
    "}\n",
    "\n",
    "mutate_scaled_config = {\n",
    "    \"nodeProperties\": [\"degree\"],\n",
    "    \"mutateProperty\": \"scaledDegree\",\n",
    "    \"scaler\": \"Mean\"\n",
    "}\n",
    "\n",
    "mutate_article_rank_config = {\n",
    "    \"mutateProperty\": \"articleRank\"\n",
    "}\n",
    "\n",
    "mutate_closeness_config = {\n",
    "    \"mutateProperty\": \"closeness\"\n",
    "}\n",
    "\n",
    "# Define the Cypher queries for mutating algorithms\n",
    "mutate_fastrp_query = \"\"\"\n",
    "CALL gds.fastRP.mutate('prediction_graph', $mutate_fastrp_config)\n",
    "\"\"\"\n",
    "\n",
    "# Mutation query to apply the FastRP algorithm on the prediction graph\n",
    "\n",
    "mutate_degree_query = \"\"\"\n",
    "CALL gds.degree.mutate('prediction_graph', $mutate_degree_config)\n",
    "\"\"\"\n",
    "\n",
    "# Mutation query to calculate the degree centrality for nodes in the prediction graph\n",
    "\n",
    "mutate_scaled_query = \"\"\"\n",
    "CALL gds.scaleProperties.mutate('prediction_graph', $mutate_scaled_config)\n",
    "\"\"\"\n",
    "\n",
    "# Mutation query to scale the degree centrality values for nodes in the prediction graph\n",
    "\n",
    "mutate_article_rank_query = \"\"\"\n",
    "CALL gds.articleRank.mutate('prediction_graph', $mutate_article_rank_config)\n",
    "\"\"\"\n",
    "\n",
    "# Mutation query to calculate the article rank centrality for nodes in the prediction graph\n",
    "\n",
    "mutate_closeness_query = \"\"\"\n",
    "CALL gds.betweenness.mutate('prediction_graph', $mutate_closeness_config)\n",
    "\"\"\"\n",
    "\n",
    "# Mutation query to calculate the closeness centrality for nodes in the prediction graph\n",
    "\n",
    "stream_node_properties_query = \"\"\"\n",
    "CALL gds.graph.nodeProperties.stream('prediction_graph', ['fastRP', 'degree', 'scaledDegree', 'articleRank', 'closeness'])\n",
    "YIELD nodeId, nodeProperty, propertyValue\n",
    "RETURN nodeId AS ID, gds.util.asNode(nodeId).shortName AS datasetName, gds.util.asNode(nodeId).name AS keywordName, nodeProperty, propertyValue\n",
    "\"\"\"\n",
    "\n",
    "# Query to stream node properties after mutation for visualization or further analysis\n",
    "\n",
    "# Execute the Cypher queries for mutating algorithms\n",
    "with driver.session() as session:\n",
    "    session.run(mutate_fastrp_query, mutate_fastrp_config=mutate_fastrp_config)  # Execute FastRP mutation\n",
    "    #This query applies the FastRP algorithm to calculate node embeddings for the nodes in the prediction graph. FastRP is a scalable algorithm for computing node embeddings in large graphs.\n",
    "    #The results will update the graph with new node properties containing the embeddings calculated by FastRP.\n",
    "    session.run(mutate_degree_query, mutate_degree_config=mutate_degree_config)  # Execute Degree mutation\n",
    "    #This query calculates the degree centrality for each node in the prediction graph. Degree centrality measures the number of edges connected to a node.\n",
    "    #The results will update the graph with new node properties containing the degree centrality values for each node.\n",
    "    session.run(mutate_scaled_query, mutate_scaled_config=mutate_scaled_config)  # Execute Scaled Degree mutation\n",
    "    #This query scales the degree centrality values computed in the previous step. Scaling is often performed to normalize the centrality values and make them comparable across different nodes.\n",
    "    #The results will update the graph with new node properties containing the scaled degree centrality values for each node.\n",
    "    session.run(mutate_article_rank_query, mutate_article_rank_config=mutate_article_rank_config)  # Execute Article Rank mutation\n",
    "    #This query calculates the article rank centrality for each node in the prediction graph. ArticleRank is similar to PageRank but is specifically designed for citation networks.\n",
    "    #The results will update the graph with new node properties containing the article rank centrality values for each node.\n",
    "    session.run(mutate_closeness_query, mutate_closeness_config=mutate_closeness_config)  # Execute Closeness mutation\n",
    "    #This query calculates the closeness centrality for each node in the prediction graph. Closeness centrality measures how close a node is to all other nodes in the graph.\n",
    "    #The results will update the graph with new node properties containing the closeness centrality values for each node\n",
    "    session.run(stream_node_properties_query)  # Stream node properties after mutation\n",
    "    #This query streams the node properties after mutation for visualization or further analysis. It retrieves the node IDs, node properties, and their corresponding values.\n",
    "    #The results can be used to examine the updated properties of nodes in the prediction graph after applying the mutation algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
